{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s5e12/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e12/test.csv')\n",
    "orig = pd.read_csv('/kaggle/input/diabetes-health-indicators-dataset/diabetes_dataset.csv')\n",
    "\n",
    "TARGET = 'diagnosed_diabetes'\n",
    "print(f'Train: {train.shape}, Test: {test.shape}, Original: {orig.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect cutoff using rolling mean of physical_activity_minutes_per_week\n",
    "target_col = 'physical_activity_minutes_per_week'\n",
    "window_size = 1000\n",
    "rolling_mean = train[target_col].rolling(window=window_size).mean()\n",
    "\n",
    "threshold = 88\n",
    "cutoff_mask = rolling_mean > threshold\n",
    "cutoff_id = rolling_mean[cutoff_mask].index.min()\n",
    "\n",
    "print(f'Cutoff ID detected: {cutoff_id}')\n",
    "print(f'Train before cutoff: {cutoff_id}')\n",
    "print(f'Train after cutoff (test-like): {len(train) - cutoff_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial validation to confirm post-cutoff matches test\n",
    "print('\\nAdversarial Validation...')\n",
    "train_subset = train[train.index >= cutoff_id].copy()\n",
    "test_subset = test.copy()\n",
    "\n",
    "train_subset['is_test'] = 0\n",
    "test_subset['is_test'] = 1\n",
    "\n",
    "adv_data = pd.concat([train_subset, test_subset], ignore_index=True)\n",
    "adv_data = adv_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "drop_cols = ['id', 'is_test', TARGET]\n",
    "features_adv = [c for c in test.columns if c not in drop_cols]\n",
    "\n",
    "X_adv = adv_data[features_adv]\n",
    "y_adv = adv_data['is_test']\n",
    "\n",
    "for col in X_adv.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_adv[col] = le.fit_transform(X_adv[col].astype(str))\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_adv, y_adv)):\n",
    "    X_tr, X_vl = X_adv.iloc[train_idx], X_adv.iloc[val_idx]\n",
    "    y_tr, y_vl = y_adv.iloc[train_idx], y_adv.iloc[val_idx]\n",
    "    \n",
    "    model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    preds = model.predict_proba(X_vl)[:, 1]\n",
    "    score = roc_auc_score(y_vl, preds)\n",
    "    auc_scores.append(score)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "print(f'Adversarial Validation AUC: {mean_auc:.4f}')\n",
    "print(f'(Close to 0.5 = post-cutoff train matches test distribution)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base features\n",
    "BASE = [col for col in train.columns if col not in ['id', TARGET]]\n",
    "CATS = train.select_dtypes('object').columns.to_list()\n",
    "NUMS = [col for col in BASE if col not in CATS]\n",
    "\n",
    "print(f'{len(BASE)} Base Features')\n",
    "print(f'{len(CATS)} Categorical Features')\n",
    "print(f'{len(NUMS)} Numerical Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features from original dataset\n",
    "print('\\nCreating features from original dataset...')\n",
    "\n",
    "ORIG = []\n",
    "for col in BASE:\n",
    "    # Mean target by column value in original dataset\n",
    "    mean_map = orig.groupby(col)[TARGET].mean()\n",
    "    new_mean_col_name = f'orig_mean_{col}'\n",
    "    mean_map.name = new_mean_col_name\n",
    "    \n",
    "    train = train.merge(mean_map, on=col, how='left')\n",
    "    test = test.merge(mean_map, on=col, how='left')\n",
    "    ORIG.append(new_mean_col_name)\n",
    "    \n",
    "    # Count of samples in original dataset\n",
    "    new_count_col_name = f'orig_count_{col}'\n",
    "    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n",
    "    \n",
    "    train = train.merge(count_map, on=col, how='left')\n",
    "    test = test.merge(count_map, on=col, how='left')\n",
    "    ORIG.append(new_count_col_name)\n",
    "\n",
    "print(f'{len(ORIG)} Original Dataset Features Created!')\n",
    "FEATURES = BASE + ORIG\n",
    "print(f'{len(FEATURES)} Total Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split based on detected cutoff\n",
    "train_df = train[train['id'] < cutoff_id].copy()\n",
    "val_df = train[train['id'] >= cutoff_id].copy()\n",
    "\n",
    "X_train = train_df[FEATURES]\n",
    "y_train = train_df[TARGET]\n",
    "X_val = val_df[FEATURES]\n",
    "y_val = val_df[TARGET]\n",
    "\n",
    "print(f'Train: {X_train.shape}')\n",
    "print(f'Validation (test-like): {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set categorical columns for XGBoost\n",
    "for col in CATS:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_val[col] = X_val[col].astype('category')\n",
    "    test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost with early stopping\n",
    "print('Training XGBoost...')\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    enable_categorical=True,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "y_pred_val = xgb_model.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, y_pred_val)\n",
    "\n",
    "print(f'\\nValidation AUC: {val_auc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also train LightGBM for ensemble\n",
    "print('\\nTraining LightGBM...')\n",
    "\n",
    "# Convert categorical back to codes for LightGBM\n",
    "X_train_lgb = X_train.copy()\n",
    "X_val_lgb = X_val.copy()\n",
    "test_lgb = test[FEATURES].copy()\n",
    "\n",
    "for col in CATS:\n",
    "    le = LabelEncoder()\n",
    "    X_train_lgb[col] = le.fit_transform(X_train_lgb[col].astype(str))\n",
    "    X_val_lgb[col] = le.transform(X_val_lgb[col].astype(str))\n",
    "    test_lgb[col] = le.transform(test_lgb[col].astype(str))\n",
    "\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    num_leaves=40,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train_lgb, y_train,\n",
    "    eval_set=[(X_val_lgb, y_val)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "y_pred_val_lgb = lgb_model.predict_proba(X_val_lgb)[:, 1]\n",
    "val_auc_lgb = roc_auc_score(y_val, y_pred_val_lgb)\n",
    "\n",
    "print(f'LightGBM Validation AUC: {val_auc_lgb:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ensemble weights\n",
    "print('\\nOptimizing ensemble weights...')\n",
    "\n",
    "best_score = max(val_auc, val_auc_lgb)\n",
    "best_weight = 1.0 if val_auc > val_auc_lgb else 0.0\n",
    "\n",
    "for w in np.arange(0.0, 1.01, 0.1):\n",
    "    pred_ens = w * y_pred_val + (1 - w) * y_pred_val_lgb\n",
    "    score = roc_auc_score(y_val, pred_ens)\n",
    "    print(f'XGB={w:.1f}, LGB={1-w:.1f}: {score:.5f}')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_weight = w\n",
    "\n",
    "print(f'\\nBest Ensemble: XGB={best_weight:.1f}, LGB={1-best_weight:.1f}')\n",
    "print(f'Best Validation AUC: {best_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print('\\nGenerating predictions...')\n",
    "\n",
    "test_preds_xgb = xgb_model.predict_proba(test[FEATURES])[:, 1]\n",
    "test_preds_lgb = lgb_model.predict_proba(test_lgb)[:, 1]\n",
    "test_preds = best_weight * test_preds_xgb + (1 - best_weight) * test_preds_lgb\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    TARGET: test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print('='*70)\n",
    "print('SUBMISSION CREATED')\n",
    "print('='*70)\n",
    "print('Strategy:')\n",
    "print(f'  - Cutoff detection: ID {cutoff_id}')\n",
    "print(f'  - Adversarial validation AUC: {mean_auc:.4f} (close to 0.5 = good)')\n",
    "print(f'  - Original dataset features: {len(ORIG)} features')\n",
    "print(f'  - Total features: {len(FEATURES)}')\n",
    "print(f'  - XGBoost + LightGBM ensemble')\n",
    "print(f'  - Optimal weights: XGB={best_weight:.1f}, LGB={1-best_weight:.1f}')\n",
    "print('='*70)\n",
    "print(f'Validation AUC: {best_score:.5f}')\n",
    "print(f'Expected LB: {best_score:.5f} Â± 0.001')\n",
    "print('='*70)\n",
    "print('\\nSubmission statistics:')\n",
    "print(submission[TARGET].describe())\n",
    "print('='*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
